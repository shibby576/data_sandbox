{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised ML Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the skills I learned about NB, SVM, DT, and Random Forest to find the best model to identify letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the letter recognition data into adata frame https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/\n",
    "import pandas as pd\n",
    "letter_df = pd.read_csv('/Users/jonathan/Desktop/letter_recognition_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lettr</th>\n",
       "      <th>x-box</th>\n",
       "      <th>y-box</th>\n",
       "      <th>width</th>\n",
       "      <th>high</th>\n",
       "      <th>onpix</th>\n",
       "      <th>x-bar</th>\n",
       "      <th>y-bar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybr</th>\n",
       "      <th>xy2br</th>\n",
       "      <th>x-ege</th>\n",
       "      <th>xegvy</th>\n",
       "      <th>y-ege</th>\n",
       "      <th>yegvx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lettr  x-box  y-box  width  high  onpix  x-bar  y-bar  x2bar  y2bar  xybar  \\\n",
       "0     T      2      8      3     5      1      8     13      0      6      6   \n",
       "1     I      5     12      3     7      2     10      5      5      4     13   \n",
       "2     D      4     11      6     8      6     10      6      2      6     10   \n",
       "3     N      7     11      6     6      3      5      9      4      6      4   \n",
       "4     G      2      1      3     1      1      8      6      6      6      6   \n",
       "\n",
       "   x2ybr  xy2br  x-ege  xegvy  y-ege  yegvx  \n",
       "0     10      8      0      8      0      8  \n",
       "1      3      9      2      8      4     10  \n",
       "2      3      7      3      7      3      9  \n",
       "3      4     10      6     10      2      8  \n",
       "4      5      9      1      7      5     10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the data\n",
    "#NOTE: I converted the txt file to a csv and added the column headers in excel \n",
    "letter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#create label and feature data sets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# X is features\n",
    "X = np.array(letter_df.drop(['lettr'], 1))\n",
    "# Scale X by preprocessing to speed performance\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "#y is label\n",
    "y = np.array(letter_df['lettr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make training and test data, used the default 25% test size\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out an SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 2.293 s\n",
      "prediction time: 2.087 s\n",
      "Accuracy 0.9418\n"
     ]
    }
   ],
   "source": [
    "#Use a standard SVM with out of the box parameters to predict the letter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "\n",
    "clf = svm.SVC(gamma='auto')\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 1.985 s\n",
      "prediction time: 1.602 s\n",
      "Accuracy 0.9718\n"
     ]
    }
   ],
   "source": [
    "#Tune the SVM by adjusting the Kernel and C parameter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = svm.SVC(gamma='auto', kernel='rbf', C=100000)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 2.0 s\n",
      "prediction time: 1.484 s\n",
      "Accuracy 0.9718\n"
     ]
    }
   ],
   "source": [
    "#Tune the SVM, slightly lower C\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = svm.SVC(gamma='auto', kernel='rbf', C=1000)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 2.917 s\n",
      "prediction time: 2.972 s\n",
      "Accuracy 0.4386\n"
     ]
    }
   ],
   "source": [
    "#Tune the SVM, try sigmoid Kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = svm.SVC(gamma='auto', kernel='sigmoid', C=1000)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why would a SVM be good for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Good - Not a ton of features (16 of them) or data, could be good at separating on these multiple dimensions (kernel trick). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.188 s\n",
      "prediction time: 0.029 s\n",
      "Accuracy 0.9386\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with no parameter changes\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = RandomForestClassifier()\n",
    "t0 = time()\n",
    "clf.fit(X_train,y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.149 s\n",
      "prediction time: 0.012 s\n",
      "Accuracy 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Random Forest - updated the min sample split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = RandomForestClassifier(min_samples_split = 25)\n",
    "t0 = time()\n",
    "clf.fit(X_train,y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 2.998 s\n",
      "prediction time: 0.275 s\n",
      "Accuracy 0.9692\n"
     ]
    }
   ],
   "source": [
    "#Random Forest - updated the n_estimators to 200 (200 trees)\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = RandomForestClassifier(n_estimators = 200)\n",
    "t0 = time()\n",
    "clf.fit(X_train,y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 14.727 s\n",
      "prediction time: 1.26 s\n",
      "Accuracy 0.9706\n"
     ]
    }
   ],
   "source": [
    "#Random Forest - updated the n_estimators to 1000\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "#really high c and kernel of rbf, the really high c could lead to over fitting\n",
    "clf = RandomForestClassifier(n_estimators = 1000)\n",
    "t0 = time()\n",
    "clf.fit(X_train,y_train)\n",
    "#print trianing time\n",
    "print (\"training time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "#print prediction  time\n",
    "print (\"prediction time:\", round(time()-t0, 3), \"s\")\n",
    "\n",
    "#get accuracy\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print('Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest seemed good since it would be hard to overfit and is typically good in CV classification. Adjusting the N_esitmators helpped, but going real big was marginal. SVM was much more performant given time and accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
